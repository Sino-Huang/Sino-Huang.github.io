<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Paper Review Collection on Sukai Huang</title>
    <link>https://sino-huang.github.io/categories/paper-review-collection/</link>
    <description>Recent content in Paper Review Collection on Sukai Huang</description>
    <image>
      <title>Sukai Huang</title>
      <url>https://sino-huang.github.io/sukai_avatar.jpg</url>
      <link>https://sino-huang.github.io/sukai_avatar.jpg</link>
    </image>
    <generator>Hugo -- 0.147.8</generator>
    <language>en</language>
    <lastBuildDate>Sun, 16 Mar 2025 23:03:05 +1100</lastBuildDate>
    <atom:link href="https://sino-huang.github.io/categories/paper-review-collection/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Awesome_life_long_rl_2025</title>
      <link>https://sino-huang.github.io/posts/awesome_life_long_rl_2025/</link>
      <pubDate>Sun, 16 Mar 2025 23:03:05 +1100</pubDate>
      <guid>https://sino-huang.github.io/posts/awesome_life_long_rl_2025/</guid>
      <description>&lt;h3 id=&#34;fine-tuning-reinforcement-learning-models-is-secretly-a-forgetting-mitigation-problem&#34;&gt;Fine-tuning Reinforcement Learning Models is Secretly a Forgetting Mitigation Problem&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://arxiv.org/pdf/2402.02868v3&#34;&gt;https://arxiv.org/pdf/2402.02868v3&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt=&#34;image-20250316230434709&#34; loading=&#34;lazy&#34; src=&#34;https://sino-huang.github.io/posts/awesome_life_long_rl_2025/image-assets/image-20250316230434709.png&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt=&#34;image-20250316231300369&#34; loading=&#34;lazy&#34; src=&#34;https://sino-huang.github.io/posts/awesome_life_long_rl_2025/image-assets/cover.png&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;lifelong-reinforcement-learning-with-modulating-masks&#34;&gt;Lifelong Reinforcement Learning with Modulating Masks&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://arxiv.org/pdf/2212.11110&#34;&gt;https://arxiv.org/pdf/2212.11110&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This has some connection with LLM + adapter Policy model.&lt;/p&gt;
&lt;p&gt;&lt;img alt=&#34;image-20250316231607110&#34; loading=&#34;lazy&#34; src=&#34;https://sino-huang.github.io/posts/awesome_life_long_rl_2025/image-assets/image-20250316231607110.png&#34;&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Awesome LLMs with Different Abstraction of Language Data 2025</title>
      <link>https://sino-huang.github.io/posts/awesome_llm_and_diff_abst_of_language_info_2025/</link>
      <pubDate>Sun, 16 Mar 2025 22:17:16 +1100</pubDate>
      <guid>https://sino-huang.github.io/posts/awesome_llm_and_diff_abst_of_language_info_2025/</guid>
      <description>&lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;p&gt;there is a lack of this research on how different level of abstraction / granularity of language instructions could affect LLMs performance in instruction following or other works.&lt;/p&gt;
&lt;h3 id=&#34;absinstruct-eliciting-abstraction-ability-from-llms-through-explanation-tuning-with-plausibility-estimation&#34;&gt;ABSINSTRUCT: Eliciting Abstraction Ability from LLMs through Explanation Tuning with Plausibility Estimation&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://arxiv.org/pdf/2402.10646&#34;&gt;https://arxiv.org/pdf/2402.10646&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt=&#34;image-20250316221951317&#34; loading=&#34;lazy&#34; src=&#34;https://sino-huang.github.io/posts/awesome_llm_and_diff_abst_of_language_info_2025/image-assets/image-20250316221951317.png&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;inference-helps-plms-conceptual-understanding-improving-the-abstract-inference-ability-with-hierarchical-conceptual-entailment-graphs&#34;&gt;Inference Helps PLMs’ Conceptual Understanding: Improving the Abstract Inference Ability with Hierarchical Conceptual Entailment Graphs&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://aclanthology.org/2024.emnlp-main.1233.pdf&#34;&gt;https://aclanthology.org/2024.emnlp-main.1233.pdf&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt=&#34;image-20250316222237547&#34; loading=&#34;lazy&#34; src=&#34;https://sino-huang.github.io/posts/awesome_llm_and_diff_abst_of_language_info_2025/image-assets/image-20250316222237547.png&#34;&gt;&lt;/p&gt;
&lt;p&gt;That is the end!&lt;/p&gt;</description>
    </item>
    <item>
      <title>Survey of LLMs for Planning 2025</title>
      <link>https://sino-huang.github.io/posts/survey_of_llm_for_planning_2025/</link>
      <pubDate>Thu, 13 Mar 2025 10:19:40 +1100</pubDate>
      <guid>https://sino-huang.github.io/posts/survey_of_llm_for_planning_2025/</guid>
      <description>&lt;h3 id=&#34;plangenllms-a-modern-survey-of-llm-planning-capabilities&#34;&gt;PlanGenLLMs: A Modern Survey of LLM Planning Capabilities&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://arxiv.org/pdf/2502.11221&#34;&gt;https://arxiv.org/pdf/2502.11221&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt=&#34;image-20250313102103580&#34; loading=&#34;lazy&#34; src=&#34;https://sino-huang.github.io/posts/survey_of_llm_for_planning_2025/image-assets/image-20250313102103580.png&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;understanding-the-planning-of-llm-agents-a-survey&#34;&gt;Understanding the planning of LLM agents: A survey&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://arxiv.org/pdf/2402.02716&#34;&gt;https://arxiv.org/pdf/2402.02716&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt=&#34;image-20250313102128028&#34; loading=&#34;lazy&#34; src=&#34;https://sino-huang.github.io/posts/survey_of_llm_for_planning_2025/image-assets/image-20250313102128028.png&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;llms-as-planning-modelers-a-survey-for-leveraging-large-language-models-to-construct-automated-planning-models&#34;&gt;LLMs as Planning Modelers: A Survey for Leveraging large Language Models to Construct Automated Planning Models&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://openreview.net/pdf?id=ebJIJkQjcE&#34;&gt;https://openreview.net/pdf?id=ebJIJkQjcE&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt=&#34;image-20250313102211808&#34; loading=&#34;lazy&#34; src=&#34;https://sino-huang.github.io/posts/survey_of_llm_for_planning_2025/image-assets/image-20250313102211808.png&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;a-survey-on-large-language-models-for-automated-planning&#34;&gt;A Survey on Large Language Models for Automated Planning&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://arxiv.org/pdf/2502.12435&#34;&gt;https://arxiv.org/pdf/2502.12435&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt=&#34;image-20250313111030804&#34; loading=&#34;lazy&#34; src=&#34;https://sino-huang.github.io/posts/survey_of_llm_for_planning_2025/image-assets/cover.png&#34;&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>HTN planning @ Pascal Bercher ANU</title>
      <link>https://sino-huang.github.io/posts/htn_planning_by_pascal_2025/</link>
      <pubDate>Wed, 05 Mar 2025 09:44:58 +1100</pubDate>
      <guid>https://sino-huang.github.io/posts/htn_planning_by_pascal_2025/</guid>
      <description>&lt;h2 id=&#34;overview-of-what-is-hierarchical-planning&#34;&gt;Overview of what is hierarchical planning&lt;/h2&gt;
&lt;p&gt;&lt;img alt=&#34;image-20250305094619303&#34; loading=&#34;lazy&#34; src=&#34;https://sino-huang.github.io/posts/htn_planning_by_pascal_2025/image-assets/cover.png&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;1-daniel-hoellers-dissertation&#34;&gt;1. Daniel Hoeller’s dissertation&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://oparu.uni-ulm.de/items/a6c64b47-76e7-4532-8179-3e215a9eac9c&#34;&gt;https://oparu.uni-ulm.de/items/a6c64b47-76e7-4532-8179-3e215a9eac9c&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;It has a summary of what is hierarchical planning&lt;/p&gt;
&lt;p&gt;&lt;img alt=&#34;image-20250305234324630&#34; loading=&#34;lazy&#34; src=&#34;https://sino-huang.github.io/posts/htn_planning_by_pascal_2025/image-assets/image-20250305234324630.png&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt=&#34;image-20250305235138374&#34; loading=&#34;lazy&#34; src=&#34;https://sino-huang.github.io/posts/htn_planning_by_pascal_2025/image-assets/image-20250305235138374.png&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt=&#34;image-20250305235553916&#34; loading=&#34;lazy&#34; src=&#34;https://sino-huang.github.io/posts/htn_planning_by_pascal_2025/image-assets/image-20250305235553916.png&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;comment&lt;/strong&gt;: a $t$ is a task id that can either refer to a $c \in C$ or an $a \in A$, but a method decompose $c$ only. Ok I see, the point, the whole thing trys to allow the set to have duplicate (? why not just claim that you have a multiset)&lt;/p&gt;</description>
    </item>
    <item>
      <title>Learning General Policies Through Sketch @ Hector Geffner</title>
      <link>https://sino-huang.github.io/posts/learning_general_policy_by_hector_2025/</link>
      <pubDate>Tue, 04 Mar 2025 12:07:13 +1100</pubDate>
      <guid>https://sino-huang.github.io/posts/learning_general_policy_by_hector_2025/</guid>
      <description>&lt;p&gt;I will list some important literatures about the topic of &lt;em&gt;learning general policies through sketches&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;The research is initiated by Blai Bonet and Hector Geffner&lt;/p&gt;
&lt;p&gt;The high level goal of the research is as follows&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;[!IMPORTANT]&lt;/p&gt;
&lt;p&gt;The construction of &lt;strong&gt;reusable&lt;/strong&gt; knowledge (transfer learning) is a central concern in (deep) reinforcement learning, but the semantic and conceptual gap between the low level techniques that are used, and the high-level representations that are required, is too large.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
