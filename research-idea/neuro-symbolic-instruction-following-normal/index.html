<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Account for Levels of Granularity of Language Instructions for Embodied Agents | Sukai Huang</title>
<meta name="keywords" content="">
<meta name="description" content="The research idea is confidential and you need password to access to the content, sorry for any inconvenience.">
<meta name="author" content="Sukai Huang">
<link rel="canonical" href="https://sino-huang.github.io/research-idea/neuro-symbolic-instruction-following-normal/">
<meta name="google-site-verification" content="IFgzhtDTVCjONQMwQsBfuf0ZyHdzUR5WFYzbWsf2Gf8">
<link crossorigin="anonymous" href="/assets/css/stylesheet.a3557e3815feeee566e11f975dc096145ea63713e4a0b4392b9e3de0d725c1b5.css" integrity="sha256-o1V&#43;OBX&#43;7uVm4R&#43;XXcCWFF6mNxPkoLQ5K5494NclwbU=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://sino-huang.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://sino-huang.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://sino-huang.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://sino-huang.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://sino-huang.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" type="application/rss+xml" href="https://sino-huang.github.io/research-idea/neuro-symbolic-instruction-following-normal/index.xml">
<link rel="alternate" hreflang="en" href="https://sino-huang.github.io/research-idea/neuro-symbolic-instruction-following-normal/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.18/dist/katex.min.css" integrity="sha384-veTAhWILPOotXm+kbR5uY7dRamYLJf58I7P+hJhjeuc7hsMAkJHTsPahAl0hBST0" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.18/dist/katex.min.js" integrity="sha384-v6mkHYHfY/4BWq54f7lQAdtIsoZZIByznQ3ZqN38OL4KCsrxo31SLlPiak7cj/Mg" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.18/dist/contrib/auto-render.min.js" integrity="sha384-hCXGrW6PitJEwbkoStFjeJxv+fSOOQKOPbJxSfM6G5sWZjAyWhXiTIIAmQqnlLlh" crossorigin="anonymous"></script>
<script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement(document.body, {
          
          
          delimiters: [
              {left: '$$', right: '$$', display: true},
              {left: '$', right: '$', display: false},
              {left: '\\(', right: '\\)', display: false},
              {left: '\\[', right: '\\]', display: true}
          ],
          
          throwOnError : false
        });
    });
</script>

      <script async src="https://www.googletagmanager.com/gtag/js?id=G-TTFTV1EWH5"></script>
      <script>
        var doNotTrack = false;
        if ( false ) {
          var dnt = (navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack);
          var doNotTrack = (dnt == "1" || dnt == "yes");
        }
        if (!doNotTrack) {
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());
          gtag('config', 'G-TTFTV1EWH5');
        }
      </script><meta property="og:url" content="https://sino-huang.github.io/research-idea/neuro-symbolic-instruction-following-normal/">
  <meta property="og:site_name" content="Sukai Huang">
  <meta property="og:title" content="Account for Levels of Granularity of Language Instructions for Embodied Agents">
  <meta property="og:description" content="The research idea is confidential and you need password to access to the content, sorry for any inconvenience.">
  <meta property="og:locale" content="en">
  <meta property="og:type" content="website">
    <meta property="og:image" content="https://sino-huang.github.io/research-idea/neuro-symbolic-instruction-following-normal/image-assets/image-20250629161302925.png">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://sino-huang.github.io/research-idea/neuro-symbolic-instruction-following-normal/image-assets/image-20250629161302925.png">
<meta name="twitter:title" content="Account for Levels of Granularity of Language Instructions for Embodied Agents">
<meta name="twitter:description" content="Sukai&#39;s academic blog - storing weekly reports and research paper reviews">


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Research-Idea",
      "item": "https://sino-huang.github.io/research-idea/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Account for Levels of Granularity of Language Instructions for Embodied Agents",
      "item": "https://sino-huang.github.io/research-idea/neuro-symbolic-instruction-following-normal/"
    }
  ]
}
</script>
</head>

<body class="list" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://sino-huang.github.io/" accesskey="h" title="Sukai Huang (Alt + H)">Sukai Huang</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)" aria-label="Toggle theme">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://sino-huang.github.io/biography/" title="Biography">
                    <span>Biography</span>
                </a>
            </li>
            <li>
                <a href="https://www.notion.so/Literature-Review-Tracker-for-Embodied-Agent-Neuro-Symbolic-AI-208396e9a0fd802a88cdec436d42509b?source=copy_link" title="Lit Reviews">
                    <span>Lit Reviews</span>&nbsp;
                    <svg fill="none" shape-rendering="geometricPrecision" stroke="currentColor" stroke-linecap="round"
                        stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12">
                        <path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"></path>
                        <path d="M15 3h6v6"></path>
                        <path d="M10 14L21 3"></path>
                    </svg>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main"> 

<header class="page-header"><div class="breadcrumbs"><a href="https://sino-huang.github.io/">Home</a>&nbsp;Â»&nbsp;<a href="https://sino-huang.github.io/research-idea/">Research-Idea</a></div>
  <h1>
    Account for Levels of Granularity of Language Instructions for Embodied Agents
    <a href="/research-idea/neuro-symbolic-instruction-following-normal/index.xml" title="RSS" aria-label="RSS">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"
        stroke-linecap="round" stroke-linejoin="round" height="23">
        <path d="M4 11a9 9 0 0 1 9 9" />
        <path d="M4 4a16 16 0 0 1 16 16" />
        <circle cx="5" cy="19" r="1" />
      </svg>
    </a>
  </h1>
</header>
<div class="post-content"><p>The research idea is confidential and you need password to access to the content, sorry for any inconvenience.</p>



<div class="hugo-encryptor-container">
  <div class="hugo-encryptor-prompt">
    <h3><strong>Encrypted Section<strong></h3>
    
      <p>Part of this article is encrypted with password:</p>
    
  </div>
  <div class="hugo-encryptor-form">
    <input
      class="hugo-encryptor-input"
      placeholder='Please input the password'
    />
    <input
      class="hugo-encryptor-button"
      type="button"
      value='Click to verify'
      onclick="_click_handler(this)"
    />
  </div>
  <div
    class="hugo-encryptor-cipher-text"
    data-password="siyang-and-monash-are-two-of-my-focus"
    style="display: none;"
  >
    <span style="display: none;">--- DON'T MODIFY THIS LINE ---</span>
    <h3 id="-1-short-motivation">ð§­ 1. <strong>Short Motivation</strong><a hidden class="anchor" aria-hidden="true" href="#-1-short-motivation">#</a></h3>
<details>
  <summary>Tips</summary>
  <div><p><strong>What is the problem you&rsquo;re tackling?</strong></p>
<p><strong>Why is it important?</strong></p>
<ul>
<li>Ground the reader in a real, compelling issue in the ML/AI landscape.</li>
<li>Mention a bottleneck, limitation, or a surprising gap in current literature.</li>
</ul>
<p><strong>Consolidate this after you find out the concrete research area and prior work</strong></p>
</div>
</details>
<ul>
<li>
<p>Neuro-symbolic approaches for embodied agents have shown impressive capabilities in following natural language instructions across diverse environments and robotic embodiments.</p>
</li>
<li>
<p>However, most existing studies assume a uniform instruction granularity &mdash; often are highly detailed and action-specific. In contrast, human instructors naturally vary the level of instruction granularity depending on the context, the learner&rsquo;s expertise, and habitual communication style.</p>
</li>
<li>
<p>Thus, we see a clear mismatch between research assumptions and real-world scenarios.</p>
</li>
</ul>
<p><img alt="image-20250703142259928" loading="lazy" src="/research-idea/neuro-symbolic-instruction-following-normal/image-assets/image-20250703142259928.png"></p>
<blockquote>
<p>[!IMPORTANT]</p>
<p>By leveraging Hector Geffnerâs Policy sketch formalism to model natural language instructions, we can <strong>systematically quantify</strong> the granularity of these instructions.</p></blockquote>
<table>
  <thead>
      <tr>
          <th>Aspect</th>
          <th>High-Level Instruction</th>
          <th>Low-Level Instruction</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>Subproblem Coverage</td>
          <td>Few subproblem are omitted (e.g., washing dishes)</td>
          <td>Full pipeline: get â cook â assemble â serve â wash</td>
      </tr>
      <tr>
          <td>Feature Count</td>
          <td>Fewer features (e.g., omit <strong>is_clean</strong> predicate for plates, or omit <strong>distance</strong> property of the target objects)</td>
          <td>More features</td>
      </tr>
      <tr>
          <td>Type Specificity</td>
          <td>General (e.g., Chop vegetables)</td>
          <td>Precise (e.g., âChop tomatoesâ)</td>
      </tr>
      <tr>
          <td><strong>Example Instruction</strong></td>
          <td>âPrepare rice, seaweed and fish, make sushi, and then serve it to the table.â</td>
          <td>âPick up rice, cook it in the top-left pot, then place it on a plate with seaweed and chopped fish. Blah blah&hellip;</td>
      </tr>
  </tbody>
</table>
<h3 id="-2-background--related-work">ð 2. <strong>Background &amp; Related Work</strong><a hidden class="anchor" aria-hidden="true" href="#-2-background--related-work">#</a></h3>
<details>
  <summary>Tips</summary>
  <div><p><strong>You shall not be the first one working on this topic.</strong> Find the prior works that are closely relevant to what you want to solve. Ask yourself &mdash; How did those works solve the research problem you target, what are the advantages and trade-offs of your approach?</p>
<blockquote>
<p>[!TIP]</p>
<p>You can design a prompt for ScholarQA</p></blockquote>
</div>
</details>
<h4 id="-topic-1-formal-representation-of-instruction-abstraction">ð§  <strong>Topic 1: Formal Representation of Instruction Abstraction</strong><a hidden class="anchor" aria-hidden="true" href="#-topic-1-formal-representation-of-instruction-abstraction">#</a></h4>
<p><strong>Prompt for ScholarQA:</strong></p>
<blockquote>
<p>What prior work has proposed <strong>formal or symbolic models</strong> to represent the <strong>abstraction level</strong> of natural language instructions in planning, robotics, or instruction-following tasks? Are there existing frameworks (e.g., program sketches, hierarchical policies, task decomposition) that allow explicit modeling or control over instruction granularity?</p></blockquote>
<details>
  <summary>Check the details for Topic 1</summary>
  <div><p><a href="https://ai2-scholar-qa.allen.ai/query/cfa8c2b1-ad07-46ca-9e17-532c7036dcc0">https://ai2-scholar-qa.allen.ai/query/cfa8c2b1-ad07-46ca-9e17-532c7036dcc0</a></p>
<p><strong>Background</strong></p>
<p>Human instructors convey NL instructions with varying levels of granularity depending on context, user expertise, and habitual communication style. This variation creates a key challenge for embodied agents: instructions can range from abstract commands (e.g., &ldquo;deliver the package&rdquo;) to detailed procedures (e.g., &ldquo;move to coordinates (x, y), ensure hands are empty, then pick up the package&rdquo;). This diverse abstraction spectrum makes it difficult for agents to adapt and ground instructions into concrete action sequences.</p>
<p>Formal and symbolic representations have emerged as a crucial bridge between the flexibility of NL and the structured representations required by computational systems [1,2], targeting several key challenges:</p>
<ol>
<li>Disambiguating vague instructions</li>
<li>Inferring implicit steps</li>
<li>Handling instructions at varying levels of abstractions</li>
</ol>
<p><strong>Related Work</strong></p>
<p>Prior works have leveraged well-established symbolic representation frameworks to map NL instructions into symbolic formalism to that support symbolic reasoning and action planning. Below, we outline three main classes of symbolic representations used for this purpose:</p>
<ol>
<li>
<p><strong>Temporal Logic</strong> has been a cornerstone method for representing time-dependent properties and constraints within instructions [6, 7]. It enables the decomposition of high-level goals into temporal subgoals [4, 8] and even serves as specification language for tasks in embodied agent benchmark simulators [5].</p>
<p><img alt="image-20250703122037576" loading="lazy" src="image-assets/image-20250703122037576.png"></p>
</li>
<li>
<p><strong>PDDL</strong> (Planning Domain Definition Language) has also been widely adopted as an intermediate formalism in embodied instruction following. Some recent works translate natural language task descriptions into PDDL [9, 10, 11], enabling the use of external symbolic planners to generate or verify action sequences. This pipeline offers robustness against hallucinations by LLM agents and provides a structured, declarative representation of tasks that supports symbolic reasoning.</p>
<p>Benchmarks like ALFWorld [12] employ PDDL to formally specify the environment. Participants are prompted to derive the worldâs PDDL representation from perceptual inputs and natural language instructions [13].</p>
<p><img alt="image-20250703121940950" loading="lazy" src="image-assets/image-20250703121940950.png"></p>
<p>However, mainstream PDDL planners have limited support for modeling expert instructions (i.e., behavior preference) [14]. The language itself also lacks expressivity for capturing different levels of granularity in expert instructions, which is the focus of our work.</p>
</li>
<li>
<p><strong>Programs as Plans.</strong> Some works represent tasks as executable programs &mdash; such as Python scripts [15] &mdash; or probabilistic programs [1], enabling structured reasoning about physical outcomes of actions. based on NL descriptions [3].</p>
<p><img alt="image-20250703122159117" loading="lazy" src="image-assets/image-20250703122159117.png"></p>
</li>
</ol>
<p><strong>Sum up</strong></p>
<p>However, most existing approaches assume a fixed (often low-level) or uniform level of granularity in instructions. The challenge of modeling instructions that vary in granularity remains under-explored. While hierarchical policy models &mdash; such as option-based MDPs [16] and architectures combining high-level planners with low-level executors [17, 18] &mdash; partially address abstract high-level instructions, their focus remains on task decomposition and policy optimization, not on modeling the semantic structure of instruction language itself. To this end, we investigate how <em>policy sketch</em> formalism &mdash; a structured representation developed recently <em>[citation]</em>, can be leveraged to explicitly account for different instruction granularity levels, thereby enabling more robust reasoning and action generation.</p>
<p><strong>Ref:</strong></p>
<p>[1] Wong, Lionel, et al. &ldquo;From word models to world models: Translating from natural language to the probabilistic language of thought.&rdquo; <em>arXiv preprint arXiv:2306.12672</em> (2023).</p>
<p>[2] Tenenbaum, Joshua B. &ldquo;Cognitive and computational building blocks for more human-like language in machines.&rdquo; (2020).</p>
<p>[3] Zhang, Cedegao, et al. &ldquo;Grounded physical language understanding with probabilistic programs and simulated worlds.&rdquo; Proceedings of the annual meeting of the cognitive science society. Vol. 45. No. 45. 2023.</p>
<p>[4] Wang, Jun, et al. &ldquo;Conformal temporal logic planning using large language models.&rdquo; <em>arXiv preprint arXiv:2309.10092</em> (2023).</p>
<p>[5] Li, Manling, et al. &ldquo;Embodied agent interface: Benchmarking llms for embodied decision making.&rdquo; <em>Advances in Neural Information Processing Systems</em> 37 (2024): 100428-100534.</p>
<p>[6] Wang, Christopher et al. âLearning a natural-language to LTL executable semantic parser for grounded robotics.â <em>Conference on Robot Learning</em> (2020).</p>
<p>[7] Yongchao Chen, Rujul Gandhi, Yang Zhang, Chuchu Fan. &ldquo;NL2TL: Transforming Natural Languages to Temporal Logics using Large Language Models.&rdquo; EMNLP 2023: 15880-15903</p>
<p>[8] Liu, Jason Xinyu, et al. &ldquo;Lang2ltl: Translating natural language commands to temporal specification with large language models.&rdquo; Workshop on Language and Robotics at CoRL 2022. 2022.</p>
<p>[9] Guan, Lin, et al. &ldquo;Leveraging pre-trained large language models to construct and utilize world models for model-based task planning.&rdquo; <em>Advances in Neural Information Processing Systems</em> 36 (2023): 79081-79094.</p>
<p>[10] Mahdavi, Sadegh et al. âLeveraging Environment Interaction for Automated PDDL Translation and Planning with Large Language Models.â <em>Neural Information Processing Systems</em> (2024).</p>
<p>[11] Huang, Sukai, Nir Lipovetzky, and Trevor Cohn. &ldquo;Planning in the Dark: LLM-Symbolic Planning Pipeline without Experts.&rdquo; <em>Proceedings of the AAAI Conference on Artificial Intelligence</em>. Vol. 39. No. 25. 2025.</p>
<p>[12] Shridhar, Mohit, et al. &ldquo;ALFWorld: Aligning Text and Embodied Environments for Interactive Learning.&rdquo; <em>International Conference on Learning Representations</em>.</p>
<p>[13] Xie, Yaqi, et al. &ldquo;Translating natural language to planning goals with large-language models.&rdquo; <em>arXiv preprint arXiv:2302.05128</em> (2023).</p>
<p>[14] Gerevini, Alfonso E., et al. &ldquo;Deterministic planning in the fifth international planning competition: PDDL3 and experimental evaluation of the planners.&rdquo; <em>Artificial Intelligence</em> 173.5-6 (2009): 619-668.</p>
<p>[15] Singh, Ishika, et al. &ldquo;ProgPrompt: program generation for situated robot task planning using large language models.&rdquo; Autonomous Robots 47.8 (2023): 999-1012.</p>
<p>[16] Andreas, Jacob, Dan Klein, and Sergey Levine. &ldquo;Modular multitask reinforcement learning with policy sketches.&rdquo; <em>International conference on machine learning</em>. PMLR, 2017.</p>
<p>[17] Wang, Zihao, et al. &ldquo;Describe, explain, plan and select: interactive planning with llms enables open-world multi-task agents.&rdquo; <em>Advances in Neural Information Processing Systems</em> 36 (2023): 34153-34189.</p>
<p>[18] Nottingham, Kolby, et al. &ldquo;Do embodied agents dream of pixelated sheep: Embodied decision making using language guided world modelling.&rdquo; <em>International Conference on Machine Learning</em>. PMLR, 2023.</p>
</div>
</details>
<h4 id="-topic-2-robustness-to-incomplete-or-underspecified-instructions">ð <strong>Topic 2: Robustness to Incomplete or Underspecified Instructions</strong><a hidden class="anchor" aria-hidden="true" href="#-topic-2-robustness-to-incomplete-or-underspecified-instructions">#</a></h4>
<p><strong>Prompt for ScholarQA:</strong></p>
<blockquote>
<p>What prior work exists on instruction-following agents that are robust to <strong>incomplete</strong>, <strong>underspecified</strong>, or <strong>ambiguous</strong> natural language instructions, particularly in embodied or interactive environments? Include approaches from both end-to-end and neuro-symbolic models that handle ambiguity, implicit goals, or missing information during execution.</p></blockquote>
<details>
  <summary>Check the details for Topic 2</summary>
  <div><p><a href="https://ai2-scholar-qa.allen.ai/query/fee23fea-c021-4d9d-9465-7e71fdd92843">https://ai2-scholar-qa.allen.ai/query/fee23fea-c021-4d9d-9465-7e71fdd92843</a></p>
<p><strong>Background</strong></p>
<p>Natural language instructions are often vague, or omit details that humans readily infer from context, but which pose significant challenges for instruction-following agents. For example, a command like <em>&ldquo;pick up the cup&rdquo;</em> may be ambiguous in an environment with multiple cups, relying on implicit contextual cuesâsuch as &ldquo;selecting the <strong>closest</strong> cup&rdquo;.</p>
<p><strong>Related Work</strong></p>
<p>Approaches to handling ambiguous or underspecified instructions can be broadly categorized into end-to-end neural methods and neuro-symbolic frameworks.</p>
<p><strong>Neural Approaches:</strong> End-to-end models often rely on large-scale training and multimodal attention mechanisms [4] to resolve ambiguity, such as those based on vision-language models like SAM [1, 2], Grounding DINO [3]. These models can leverage learned priors from pretraining to resolve some forms of reference ambiguity. However, their performance tends to degrade in out-of-distribution (OOD) environments [5] or tasks requiring compositional reasoning on novel compositions [6].</p>
<p><strong>Neuro-symbolic approaches</strong> aim to resolve ambiguity in natural language by converting instructions into formal symbolic representations. For example, some methods disambiguate linguistic paraphrases by mapping them to discrete symbolic forms [7], while some translates free-form language into structured planning languages like PDDL [8]. However, traditional symbolic languages often only support deterministic inference, which struggles to handle the inherent <strong>uncertainty</strong> of natural language. To address this, probabilistic programming languages have been proposed to explicitly model such uncertainty, offering a more flexible approach [9, 10].</p>
<p><strong>Sum up</strong></p>
<p>In this work, we investigate Geffnerâs <em>policy sketch</em> formalism, which provides a structural representation of rule-based general policy. One notable advantage of this approach is that it offers a way to quantify the ambiguity or underspecification of instructions by analyzing the time complexity of solving the corresponding subproblem via <em>width-based planning</em>. This complexity is influenced by both the <em>quality</em> of the features chosen (i.e., those aspects the instructor deems relevant) and the <em>number</em> of such features included in the sketch. Thus, policy sketches provide a insightful framework not just for interpreting abstract instructions, but also for measuring how difficult it is for an agent to act upon them, offering a principled lens on instruction ambiguity.</p>
<p><strong>Ref:</strong></p>
<p>[1] Kirillov, Alexander, et al. &ldquo;Segment anything.&rdquo; <em>Proceedings of the IEEE/CVF international conference on computer vision</em>. 2023.</p>
<p>[2] Nikhila Ravi, Valentin Gabeur, et. al. &ldquo;SAM 2: Segment Anything in Images and Videos.&rdquo; ICLR 2025</p>
<p>[3] Shilong Liu, Zhaoyang Zeng, Tianhe Ren, Feng Li, Hao Zhang, Jie Yang, Qing Jiang, Chunyuan Li, Jianwei Yang, Hang Su, Jun Zhu, Lei Zhang. &ldquo;Grounding DINO: Marrying DINO with Grounded Pre-training for Open-Set Object Detection.&rdquo; ECCV (47) 2024: 38-55</p>
<p>[4] Hill, Felix, et al. &ldquo;Human instruction-following with deep reinforcement learning via transfer-learning from text.&rdquo; <em>arXiv preprint arXiv:2005.09382</em> (2020).</p>
<p>[5] Lake, Brenden, and Marco Baroni. &ldquo;Generalization without systematicity: On the compositional skills of sequence-to-sequence recurrent networks.&rdquo; <em>International conference on machine learning</em>. PMLR, 2018.</p>
<p>[6] Press, Ofir, et al. &ldquo;Measuring and Narrowing the Compositionality Gap in Language Models.&rdquo; <em>Findings of the Association for Computational Linguistics: EMNLP 2023</em>. 2023.</p>
<p>[7] Kazutoshi Shinoda, Yuki Takezawa, Masahiro Suzuki, Yusuke Iwasawa, Yutaka Matsuo. &ldquo;Improving the Robustness to Variations of Objects and Instructions with a Neuro-Symbolic Approach for Interactive Instruction Following.&rdquo; MMM (2) 2023: 635-646</p>
<p>[8] Xie, Yaqi, et al. &ldquo;Translating natural language to planning goals with large-language models.&rdquo; <em>arXiv preprint arXiv:2302.05128</em> (2023).</p>
<p>[9] Tenenbaum, Joshua B. &ldquo;Cognitive and computational building blocks for more human-like language in machines.&rdquo; (2020).</p>
<p>[10] Wong, Lionel, et al. &ldquo;From word models to world models: Translating from natural language to the probabilistic language of thought.&rdquo; <em>arXiv preprint arXiv:2306.12672</em> (2023).</p>
</div>
</details>
<h4 id="-topic-3-curriculum-learning-of-instruction-granularity">ð <strong>Topic 3: Curriculum Learning of Instruction Granularity</strong><a hidden class="anchor" aria-hidden="true" href="#-topic-3-curriculum-learning-of-instruction-granularity">#</a></h4>
<p><strong>Prompt for ScholarQA:</strong></p>
<blockquote>
<p>What research has studied <strong>curriculum learning</strong> in instruction-following or reinforcement learning agents, specifically where the <strong>granularity or abstraction level</strong> of natural language instructions is varied over time? Are there existing studies that analyze how instruction specificity affects <strong>learning efficiency</strong> or <strong>generalization</strong>?</p></blockquote>
<details>
  <summary>Check the details for Topic 3</summary>
  <div><p><a href="https://ai2-scholar-qa.allen.ai/query/403fbe22-08b1-4ef5-bd6b-b2d666805a01">https://ai2-scholar-qa.allen.ai/query/403fbe22-08b1-4ef5-bd6b-b2d666805a01</a></p>
<p><strong>Background</strong></p>
<p>Curriculum learning in artificial intelligence is inspired by pedagogical principles in human education, where learners are exposed to concepts in a structured orderâtypically progressing from simpler to more complex tasks [1, 2]. In machine learning, curriculum learning frameworks are often organized into two key components [3]:</p>
<ol>
<li><strong>Complexity Assessment</strong> â estimating the difficulty of each task or example in order to prioritize learning.</li>
<li><strong>Scheduler Formulation</strong> â devising a strategy to sequence and pace the training data or tasks.</li>
</ol>
<p>In the context of vision-and-language navigation (VLN), <em>BabyWalk</em> [4] introduced a curriculum-based approach by incrementally training agents on navigation tasks of increasing length and complexity, thereby allowing agents to progressively acquire and integrate navigational skills.</p>
<p>While curriculum learning has been applied in various embodied AI settings, there is limited work exploring curricula based on the granularity or abstraction level of natural language instructions. The most relevant line of work involves decomposing complex tasks into sequences of simpler subtasks and learn the policy gradually [5, 6]. However, these approaches primarily focus on scaling the <em>task complexity</em> itself. In contrast, we vary the <strong>linguistic abstraction</strong> of the instruction while keeping the underlying task constant.</p>
<p>Our focus differs: we hold the core embodied task fixed and manipulate only the abstraction level of the instructions provided to the agent. The challenge lies not in solving increasingly difficult tasks, but in <strong>reasoning from instructions that vary in granularity</strong>.</p>
<p>As in Topic 2, <em>policy sketch</em> formalism not only provides a structured representation of instructions at varying abstraction levels, but also offers a means of <strong>quantifying the interpretive difficulty</strong> of a given instruction. This enables us to explore two things:</p>
<ol>
<li>
<p>We investigate whether the learning efficiency of embodied agents (e.g., VLA models) correlates with the <strong>planning width</strong> of the task sketch (a complexity metric from width-based planning formalism). A positive correlation would imply that:</p>
<ul>
<li>The model&rsquo;s learning efficiency scales polynomially with problem size (where &ldquo;size&rdquo; is quantified via the number of &ldquo;atoms&rdquo; in the grounded problem world model)
<ul>
<li>Actually I <strong>do not think</strong> the training time correlates to the <strong>planning width</strong> (otherwise we can never scale up), rather, I think the inference time (the time of action generation via denoising) may be correlates with the <strong>planning width</strong> of the policy sketch. Check the next section.</li>
</ul>
</li>
<li><strong>If correlation is found (Yes):</strong>
<ul>
<li><strong>Granularity-Sensitive Computation</strong>
<ul>
<li><em>Evidence</em>: The modelâs denoising steps scale with planning width (abstract instruction -&gt; larger width).</li>
<li><em>Implication</em>: Develops <strong>causal alignment</strong> between language structure and action generation, mirroring human-like effort allocation:
<ul>
<li>Abstract instruction -&gt; system 2 (slow, require deep reasoning)</li>
<li>Fine instruction -&gt; system 1 (fast, shallow processing, even if the number of tokens required to be processed is larger)</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><strong>If no correlation (No):</strong>
<ul>
<li><strong>Ablation Studies</strong>
<ul>
<li><em>Hypothesis</em>: Curriculum learning (low-level to abstract instruction) may artificially induce/obscure correlation.</li>
<li><em>Tests</em>:
<ul>
<li>Ablate curriculum: Train on shuffled granularity â Measure correlation strength.</li>
</ul>
</li>
<li><em>Interpretation</em>:
<ul>
<li>Stronger correlation post-ablation â Curriculum was masking granularity-sensitivity.</li>
<li>Weaker correlation â Granularity-sensitivity may require explicit architectural bias.</li>
</ul>
</li>
</ul>
</li>
<li><strong>Alternative Explanations</strong>
<ul>
<li>Check if correlation is absorbed by other factors (e.g., instruction length, object count).</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p>Design optimal instructional curricula to identify how embodied agents best learn tasks. This inquiry may yield insights into <strong>human pedagogy</strong>, such as how instruction granularity affects learning.</p>
</li>
</ol>
<p><strong>Ref:</strong></p>
<p>[1] Lee, Bruce W., Hyunsoo Cho, and Kang Min Yoo. &ldquo;Instruction Tuning with Human Curriculum.&rdquo; <em>Findings of the Association for Computational Linguistics: NAACL 2024</em>. 2024.</p>
<p>[2] Graves, Alex, et al. &ldquo;Automated curriculum learning for neural networks.&rdquo; <em>international conference on machine learning</em>. Pmlr, 2017.</p>
<p>[3] Wang, Xin, Yudong Chen, and Wenwu Zhu. &ldquo;A survey on curriculum learning.&rdquo; <em>IEEE transactions on pattern analysis and machine intelligence</em> 44.9 (2021): 4555-4576.</p>
<p>[4] Zhu, Wang, et al. &ldquo;BabyWalk: Going Farther in Vision-and-Language Navigation by Taking Baby Steps.&rdquo; <em>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</em>. 2020.</p>
<p>[5] Kravchenko, Anna, and Rhodri Cusack. &ldquo;The limitations of automatically generated curricula for continual learning.&rdquo; <em>Plos one</em> 19.4 (2024): e0290706.</p>
<p>[6] Manela, Binyamin, and Armin Biess. &ldquo;Curriculum learning with hindsight experience replay for sequential object manipulation tasks.&rdquo; <em>Neural Networks</em> 145 (2022): 260-270.</p>
</div>
</details>
<h4 id="-prompt-4-adaptive-noise-schedule-based-on-instruction-complexity-in-diffusionflow-matching-based-generative-model">ð§  <strong>Prompt 4: Adaptive Noise Schedule Based on Instruction Complexity in Diffusion/Flow Matching Based Generative Model</strong><a hidden class="anchor" aria-hidden="true" href="#-prompt-4-adaptive-noise-schedule-based-on-instruction-complexity-in-diffusionflow-matching-based-generative-model">#</a></h4>
<p><strong>Prompt for ScholarQA:</strong></p>
<blockquote>
<p>What research has explored <strong>adaptive noise scheduling</strong>, <strong>step control</strong>, or <strong>dynamic denoising strategies</strong> in <strong>diffusion models</strong> or <strong>flow matching-based generative models</strong>, especially in <strong>instruction-conditioned generation</strong>? Are there methods that estimate the <strong>complexity of conditioning input</strong> (e.g., language instructions, symbolic structure, task difficulty) and adjust the <strong>noise level</strong>, <strong>number of inference steps</strong>, or <strong>guidance scale</strong> accordingly to improve sample efficiency, quality, or reasoning alignment?</p></blockquote>
<details>
  <summary>Check the details for Topic 4</summary>
  <div><p><a href="https://ai2-scholar-qa.allen.ai/query/4ce728c6-1b94-4806-b3d2-82847e7efd26">https://ai2-scholar-qa.allen.ai/query/4ce728c6-1b94-4806-b3d2-82847e7efd26</a></p>
<p>We are not aiming to dive deeply into this topic, but rather to explore a practical hypothesis: that in VLA (vision-language-action) models where the action generation module is implemented via a flow matching-based generator, <strong>more concrete instructions should require fewer denoising steps</strong> to generate executable actions &mdash; a relationship where instruction concreteness governs the computational efficiency of action generation &mdash; more concrete instructions enable both faster convergence (fewer denoising steps)</p>
<p>To evaluate this, we take inspiration from [1] (Check <a href="https://www.notion.so/sdf-225396e9a0fd80aaaa9ee0ef27ea7cb3?source=copy_link">summary</a>) , which introduces Time Prediction Diffusion Models (TPDMs). TPDMs <strong>learn</strong> a plug-and-play <strong>scheduler</strong> that adaptively adjusts both the noise level and the total number of denoising steps during inference. The optimized scheduler allows simple prompts (e.g., <em>&ldquo;a single red apple&rdquo;</em>) to complete generation in fewer steps, while complex prompts (e.g., <em>&ldquo;an astronaut floating in space&rdquo;</em>) are allocated more steps for better fidelity.</p>
<p>In our proposed experiment, we can:</p>
<ul>
<li>Implement TPDM-style adaptive step scheduler in an instruction-conditioned flow matching action generator.</li>
<li>Measure whether low-level or explicit commands lead to consistently <strong>fewer denoising steps</strong> compared to <strong>abstract instructions</strong>.</li>
<li>Further investigate whether the <strong>optimized number of denoising steps</strong> learned by the scheduler <strong>correlates with the planning width</strong> of the policy sketch (<strong>a metric for instructional complexity</strong> (see Topic 3).</li>
</ul>
<p><strong>Ref:</strong></p>
<p>[1] Ye, Zilyu, et al. &ldquo;Schedule on the fly: Diffusion time prediction for faster and better image generation.&rdquo; <em>Proceedings of the Computer Vision and Pattern Recognition Conference</em>. 2025.</p>
</div>
</details>
<h3 id="-3-methodology-and-experiment-setup">ð§ª 3. <strong>Methodology and Experiment Setup</strong><a hidden class="anchor" aria-hidden="true" href="#-3-methodology-and-experiment-setup">#</a></h3>
<details>
  <summary>Tips</summary>
  <div><p>Break this down as appropriate to your research:</p>
<p><strong>Overall Approach</strong> â high-level method and pipeline</p>
<p><strong>Key Components</strong> â any novel model, architecture, algorithm, or setup</p>
<p><strong>Comparison or Baselines</strong> â what will you compare against? Make sure <strong>you know did the survey well and know the SOTA work</strong></p>
<p><strong>Implementation Details</strong> â how you will run this, what environment/tools/datasets</p>
</div>
</details>
<p><img alt="image-20250629172226708" loading="lazy" src="/research-idea/neuro-symbolic-instruction-following-normal/image-assets/image-20250629172226708.png"></p>
<p><img alt="image-20250629172241487" loading="lazy" src="/research-idea/neuro-symbolic-instruction-following-normal/image-assets/image-20250629172241487.png"></p>
<h4 id="overall-approach">Overall Approach<a hidden class="anchor" aria-hidden="true" href="#overall-approach">#</a></h4>
<p>The embodied agent we use is</p>
<ol>
<li>Finetuning <a href="https://www.notion.so/SmolVLA-A-Vision-Language-Action-Model-for-Affordable-and-Efficient-Robotics-20b396e9a0fd802894f1f0c013ca8be3?source=copy_link">SmolVLA</a> model</li>
<li>Finetuning <a href="https://github.com/microsoft/Magma">Magma</a> (4 x A100 GPUs may be required, ask Reza for help)</li>
</ol>
<p>Check the diagram to see how policy sketch is involved.</p>
<details>
  <summary>Diagram</summary>
  <div><img alt="image-20250703223823068" loading="lazy" src="image-assets/image-20250703223823068.png"></div>
</details>
<h4 id="key-components">Key Components<a hidden class="anchor" aria-hidden="true" href="#key-components">#</a></h4>
<ul>
<li>
<p>The mapping from natural language to policy sketch</p>
<ul>
<li>we need to collect training data for this mapping for different environments
<ul>
<li>three stage training data
<ul>
<li>Stage 1: image + NL instruction -&gt; target features and policy sketches</li>
<li>Stage 2:  image + policy sketches -&gt; which policy sketch is activated</li>
<li>Stage 3: target features and activated policy sketch + image -&gt; ground truth action and whether the policy sketch is completed
<ul>
<li>Borrowing the idea of <a href="https://arxiv.org/abs/2207.12598">Classifier-Free Diffusion Guidance</a>. During training, randomly replace sketches with:
<ul>
<li><em>Abstract versions</em> (higher-level goals, e.g., &ldquo;Grasp tool&rdquo; instead of &ldquo;Close gripper to 5cm&rdquo;)</li>
<li><em>Concrete versions</em> (detailed sub-actions)</li>
<li><em><code>null</code></em> (10% probability) â Forces <em>visual improvisation</em>:
<ul>
<li>The agent must infer actions solely from target features and image context.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>Justification of the translation
<ul>
<li>Check this Safe RL <a href="https://www.notion.so/Safe-Reinforcement-Learning-with-Free-form-Natural-Language-Constraints-and-Pre-Trained-Language-Mod-21d396e9a0fd8077b9d9de6db6eb4e79?source=copy_link">work</a>
<ul>
<li>condensed version of the NL instruction can be semantically vague.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p>We may want to further train and eval the VLM to</p>
<ul>
<li>Grounding high level policy sketches into low level policy sketches</li>
<li>Recover missing policy sketch</li>
</ul>
</li>
</ul>
<h4 id="comparison">Comparison<a hidden class="anchor" aria-hidden="true" href="#comparison">#</a></h4>
<p>Given that this is the modification of the NL output of VLM into the corresponding symbolic representation. We therefore can compare our approach with</p>
<ol>
<li>Raw SmolVLA</li>
<li>Raw OpenVLA</li>
<li>Classical planner (check whether the inference time of VLA correlates to the planning time), only available in PDDLGym env</li>
</ol>
<h4 id="experimental-design">Experimental design<a hidden class="anchor" aria-hidden="true" href="#experimental-design">#</a></h4>
<p><strong>Topic 1</strong></p>
<ol>
<li>Comparing the performance with baselines</li>
<li>Evaluate generalization performance
<ol>
<li>Environment map size and training instance size</li>
<li>transfer learning to new environment</li>
</ol>
</li>
</ol>
<p><strong>Topic 2</strong></p>
<ol>
<li>Re-plan the action by upgrade or downgrade the policy sketch</li>
<li>Recover missing policy sketch</li>
</ol>
<p><strong>Topic 3</strong></p>
<ol>
<li>analyze the learning efficiency of varying width of the policy sketch
<ol>
<li>check whether the learning time / inference time correlates with the width of the policy sketch</li>
</ol>
</li>
<li>learn a curriculum scheduler that can gives the best learning efficiency</li>
</ol>
<p><strong>Topic 4</strong></p>
<ul>
<li>already discussed already in the ð 2. <strong>Background &amp; Related Work</strong> section, train a TPDM-style adaptive step scheduler and prove the hypothesis.</li>
</ul>
<h4 id="implementation-details">Implementation Details<a hidden class="anchor" aria-hidden="true" href="#implementation-details">#</a></h4>
<p>Testing Environments:</p>
<ol>
<li><a href="https://github.com/StanfordVL/mini_behavior">Mini-Behavior</a></li>
<li><a href="https://github.com/tomsilver/pddlgym">PDDLGym</a></li>
<li><a href="https://github.com/VT-Collab/overcooked">Overcooked AI</a></li>
</ol>
<h3 id="-4-expected-contributions-and-abstract-draft">ð§  4. <strong>Expected Contributions and Abstract Draft</strong><a hidden class="anchor" aria-hidden="true" href="#-4-expected-contributions-and-abstract-draft">#</a></h3>
<details>
  <summary>Tips</summary>
  <div>Be direct. For example: A novel method, New benchmark, Theoretical analysis, Neuro-symbolic framework that integrating some symbolic structure into the internal computation or representation of agents.</div>
</details>
<h4 id="contribution-paragraph-draft">Contribution Paragraph Draft<a hidden class="anchor" aria-hidden="true" href="#contribution-paragraph-draft">#</a></h4>
<ul>
<li>
<p>Propose Policy Sketch to account for the levels of granularity of NL instructions and model the complexity based on the width of the sketch</p>
<ul>
<li>or we say we propose a computational model that maps natural language instructions into symbolic policy sketch, which provide a formal basis for granularity measurement and problem decomposition.</li>
</ul>
</li>
<li>
<p>We design the architecture and training for this Neuro-Symbolic instruction following AI</p>
</li>
<li>
<p>Propose a novel evaluation to fit the research study we focus on</p>
</li>
</ul>
<h4 id="abstract-draft">Abstract Draft<a hidden class="anchor" aria-hidden="true" href="#abstract-draft">#</a></h4>
<ol>
<li>Opening: Broad context and motivation
<ul>
<li>Neuro-symbolic approaches for embodied agents have shown impressive capabilities in following natural language instructions across diverse environments and robotic embodiments.</li>
</ul>
</li>
<li>Problem Statement / Gap
<ul>
<li>However, most existing studies assume a uniform, low-level instruction granularityâwhere all instructions are highly detailed and action-specific. In contrast, human instructors naturally vary the level of instruction granularity depending on the context, the learner&rsquo;s expertise, and habitual communication style.</li>
</ul>
</li>
<li>Research Question / Aim</li>
</ol>
<ul>
<li>In this paper, we address this gap by investigating how natural language instructions can be mapped into symbolic representations that explicitly account for varying levels of granularity. To formalize this variation, we leverage the policy sketch formalism from automated planning, enabling a structured representation of instruction abstraction levels.</li>
</ul>
<ol start="4">
<li>Main Finding</li>
<li>Comparative Evaluation</li>
<li>Deeper Insight / Secondary Result</li>
<li>Generalization</li>
<li>Conclusion / Broader Implications</li>
</ol>
<h3 id="-5-timeline-and-milestone">ð 5. <strong>Timeline and Milestone</strong><a hidden class="anchor" aria-hidden="true" href="#-5-timeline-and-milestone">#</a></h3>
<table>
  <thead>
      <tr>
          <th>Timeframe</th>
          <th>Milestone Description</th>
          <th>Deliverable(s)</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>June - 5 July</td>
          <td>Literature review on VLA and instruction granularity, Policy Sketch</td>
          <td>Annotated bibliography, summary</td>
      </tr>
      <tr>
          <td>6 July - 16 July</td>
          <td>Environment setup and baseline replication (3 Envs, 2 VLAs)</td>
          <td>Train the baseline model (2) among 3 Envs</td>
      </tr>
      <tr>
          <td>17 July - 25 July</td>
          <td>Design Hector&rsquo;s policy sketches for PDDLGym</td>
          <td>PDDLGym the training data are collected</td>
      </tr>
      <tr>
          <td>25 July - 31 July</td>
          <td>Design Hector&rsquo;s policy sketches for other envs and setup training scripts</td>
          <td>Full training Dataset + training scripts (T1.1, T2.1, T2.2, T3.1)</td>
      </tr>
      <tr>
          <td>1 Aug - 8 Aug</td>
          <td>Model training + Manuscript writing (ICLR)</td>
          <td>Training logs and plots for T1.1, T2.1, T2.2 T3.1</td>
      </tr>
      <tr>
          <td>9 Aug - 13 Aug</td>
          <td>Evaluation T1.1, T2.1, T2.2 T3.1, T1.2</td>
          <td>Collecting results, visualizations</td>
      </tr>
      <tr>
          <td>14 Aug - 20 Aug</td>
          <td>Training and eval T3.2 , T4</td>
          <td>A curve plot showing the optimal instruction granularity schedule (abstract-to-detailed ratio over training time) and its impact on learning efficiency and generalization; The result of whether the action inference time correlates with the width of the sketch</td>
      </tr>
      <tr>
          <td>21 Aug - 26 Aug</td>
          <td>Analysis and insight synthesis</td>
          <td>Finalize results, visualizations</td>
      </tr>
      <tr>
          <td>27 Aug - 1 Sep</td>
          <td>Paper drafting</td>
          <td>Initial paper draft, figures</td>
      </tr>
      <tr>
          <td>1 Sep - 24 Sep</td>
          <td>Internal review and final submission</td>
          <td>Final version, submission to ICLR</td>
      </tr>
  </tbody>
</table>
<h3 id="-6-future-extension">ð± 6. <strong>Future Extension</strong><a hidden class="anchor" aria-hidden="true" href="#-6-future-extension">#</a></h3>
<ol>
<li>
<p>Adapt to 3D and egocentric view (partial observability) (ALFRED environment) -&gt; can collaborate with Boying</p>
</li>
<li>
<p>Again in 3D environment, how the level of granularity of instruction interacts with the coarse-to-fine vision Semantics (boying)</p>
</li>
</ol>

  </div>
</div>
<script>
  
  document.querySelector(".hugo-encryptor-input").addEventListener("keyup", event => {
      if(event.key !== "Enter") return; 
      document.querySelector(".hugo-encryptor-button").click(); 
      event.preventDefault(); 
  });
</script>

</div>
<footer class="page-footer">
  <ul class="post-tags">
  </ul>
  <nav class="pagination">
  </nav>
</footer>
    </main>
    
<footer class="footer">
        <span>&copy; 2025 <a href="https://sino-huang.github.io/">Sukai Huang</a></span> Â· 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
