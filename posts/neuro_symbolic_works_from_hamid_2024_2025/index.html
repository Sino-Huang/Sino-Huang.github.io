<!DOCTYPE html>
<html dir="auto" lang="en">
<head><meta charset="utf-8"/>
<meta content="IE=edge" http-equiv="X-UA-Compatible"/>
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<meta content="index, follow" name="robots"/>
<title>Neuro Symbolic Works From A.Prof. Hamid @ Monash | Sukai Huang</title>
<meta content="neuro-symbolic" name="keywords"/>
<meta content="There are three papers from A.Prof. Hamid Rezatofighi :https://vl4ai.erc.monash.edu/positions.html

NAVER: A Neuro-Symbolic Compositional Automaton for Visual Grounding
with Explicit Logic Reasoning
NEUSIS: A Compositional Neuro-Symbolic Framework for Autonomous Perception, Reasoning, and Planning in Complex UAV Search Missions
HYDRA: A Hyper Agent for Dynamic Compositional Visual Reasoning



 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57


# input bibtex here
1. 
@misc{cai2025naverneurosymboliccompositionalautomaton,
      title={NAVER: A Neuro-Symbolic Compositional Automaton for Visual Grounding with Explicit Logic Reasoning}, 
      author={Zhixi Cai and Fucai Ke and Simindokht Jahangard and Maria Garcia de la Banda and Reza Haffari and Peter J. Stuckey and Hamid Rezatofighi},
      year={2025},
      eprint={2502.00372},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2502.00372}, 
}

2. 

@article{DBLP:journals/corr/abs-2409-10196,
  author       = {Zhixi Cai and
                  Cristian Rojas Cardenas and
                  Kevin Leo and
                  Chenyuan Zhang and
                  Kal Backman and
                  Hanbing Li and
                  Boying Li and
                  Mahsa Ghorbanali and
                  Stavya Datta and
                  Lizhen Qu and
                  Julian Gutierrez Santiago and
                  Alexey Ignatiev and
                  Yuan{-}Fang Li and
                  Mor Vered and
                  Peter J. Stuckey and
                  Maria Garcia de la Banda and
                  Hamid Rezatofighi},
  title        = {{NEUSIS:} {A} Compositional Neuro-Symbolic Framework for Autonomous
                  Perception, Reasoning, and Planning in Complex {UAV} Search Missions},
  journal      = {CoRR},
  volume       = {abs/2409.10196},
  year         = {2024}
}



3. 
@inproceedings{DBLP:conf/eccv/KeCJWHR24,
  author       = {Fucai Ke and
                  Zhixi Cai and
                  Simindokht Jahangard and
                  Weiqing Wang and
                  Pari Delir Haghighi and
                  Hamid Rezatofighi},
  title        = {{HYDRA:} {A} Hyper Agent for Dynamic Compositional Visual Reasoning},
  booktitle    = {{ECCV} {(20)}},
  series       = {Lecture Notes in Computer Science},
  volume       = {15078},
  pages        = {132--149},
  publisher    = {Springer},
  year         = {2024}
}


NAVER: A Neuro-Symbolic Compositional Automaton for Visual Grounding
(https://arxiv.org/abs/2502.00372)" name="description"/>
<meta content="Sukai Huang" name="author"/>
<link href="https://sino-huang.github.io/posts/neuro_symbolic_works_from_hamid_2024_2025/" rel="canonical"/>
<meta content="IFgzhtDTVCjONQMwQsBfuf0ZyHdzUR5WFYzbWsf2Gf8" name="google-site-verification"/>
<link as="style" crossorigin="anonymous" href="/assets/css/stylesheet.d6fcd20a4fb86efa4dfac8ec95da60244cc8871042183da1ef28e3a762ad79c8.css" integrity="sha256-1vzSCk+4bvpN+sjsldpgJEzIhxBCGD2h7yjjp2Ktecg=" rel="preload stylesheet"/>
<link href="https://sino-huang.github.io/favicon.ico" rel="icon"/>
<link href="https://sino-huang.github.io/favicon-16x16.png" rel="icon" sizes="16x16" type="image/png"/>
<link href="https://sino-huang.github.io/favicon-32x32.png" rel="icon" sizes="32x32" type="image/png"/>
<link href="https://sino-huang.github.io/apple-touch-icon.png" rel="apple-touch-icon"/>
<link href="https://sino-huang.github.io/safari-pinned-tab.svg" rel="mask-icon"/>
<meta content="#2e2e33" name="theme-color"/>
<meta content="#2e2e33" name="msapplication-TileColor"/>
<link href="https://sino-huang.github.io/posts/neuro_symbolic_works_from_hamid_2024_2025/" hreflang="en" rel="alternate"/>
<noscript>
<style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
<style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
<link crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/katex@0.16.18/dist/katex.min.css" integrity="sha384-veTAhWILPOotXm+kbR5uY7dRamYLJf58I7P+hJhjeuc7hsMAkJHTsPahAl0hBST0" rel="stylesheet"/>
<script crossorigin="anonymous" defer="" integrity="sha384-v6mkHYHfY/4BWq54f7lQAdtIsoZZIByznQ3ZqN38OL4KCsrxo31SLlPiak7cj/Mg" src="https://cdn.jsdelivr.net/npm/katex@0.16.18/dist/katex.min.js"></script>
<script crossorigin="anonymous" defer="" integrity="sha384-hCXGrW6PitJEwbkoStFjeJxv+fSOOQKOPbJxSfM6G5sWZjAyWhXiTIIAmQqnlLlh" src="https://cdn.jsdelivr.net/npm/katex@0.16.18/dist/contrib/auto-render.min.js"></script>
<script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement(document.body, {
          
          
          delimiters: [
              {left: '$$', right: '$$', display: true},
              {left: '$', right: '$', display: false},
              {left: '\\(', right: '\\)', display: false},
              {left: '\\[', right: '\\]', display: true}
          ],
          
          throwOnError : false
        });
    });
</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-TTFTV1EWH5"></script>
<script>
        var doNotTrack = false;
        if ( false ) {
          var dnt = (navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack);
          var doNotTrack = (dnt == "1" || dnt == "yes");
        }
        if (!doNotTrack) {
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());
          gtag('config', 'G-TTFTV1EWH5');
        }
      </script><meta content="https://sino-huang.github.io/posts/neuro_symbolic_works_from_hamid_2024_2025/" property="og:url"/>
<meta content="Sukai Huang" property="og:site_name"/>
<meta content="Neuro Symbolic Works From A.Prof. Hamid @ Monash" property="og:title"/>
<meta content="There are three papers from A.Prof. Hamid Rezatofighi :https://vl4ai.erc.monash.edu/positions.html
NAVER: A Neuro-Symbolic Compositional Automaton for Visual Grounding with Explicit Logic Reasoning NEUSIS: A Compositional Neuro-Symbolic Framework for Autonomous Perception, Reasoning, and Planning in Complex UAV Search Missions HYDRA: A Hyper Agent for Dynamic Compositional Visual Reasoning 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 # input bibtex here 1. @misc{cai2025naverneurosymboliccompositionalautomaton, title={NAVER: A Neuro-Symbolic Compositional Automaton for Visual Grounding with Explicit Logic Reasoning}, author={Zhixi Cai and Fucai Ke and Simindokht Jahangard and Maria Garcia de la Banda and Reza Haffari and Peter J. Stuckey and Hamid Rezatofighi}, year={2025}, eprint={2502.00372}, archivePrefix={arXiv}, primaryClass={cs.CV}, url={https://arxiv.org/abs/2502.00372}, } 2. @article{DBLP:journals/corr/abs-2409-10196, author = {Zhixi Cai and Cristian Rojas Cardenas and Kevin Leo and Chenyuan Zhang and Kal Backman and Hanbing Li and Boying Li and Mahsa Ghorbanali and Stavya Datta and Lizhen Qu and Julian Gutierrez Santiago and Alexey Ignatiev and Yuan{-}Fang Li and Mor Vered and Peter J. Stuckey and Maria Garcia de la Banda and Hamid Rezatofighi}, title = {{NEUSIS:} {A} Compositional Neuro-Symbolic Framework for Autonomous Perception, Reasoning, and Planning in Complex {UAV} Search Missions}, journal = {CoRR}, volume = {abs/2409.10196}, year = {2024} } 3. @inproceedings{DBLP:conf/eccv/KeCJWHR24, author = {Fucai Ke and Zhixi Cai and Simindokht Jahangard and Weiqing Wang and Pari Delir Haghighi and Hamid Rezatofighi}, title = {{HYDRA:} {A} Hyper Agent for Dynamic Compositional Visual Reasoning}, booktitle = {{ECCV} {(20)}}, series = {Lecture Notes in Computer Science}, volume = {15078}, pages = {132--149}, publisher = {Springer}, year = {2024} } NAVER: A Neuro-Symbolic Compositional Automaton for Visual Grounding (https://arxiv.org/abs/2502.00372)" property="og:description"/>
<meta content="en" property="og:locale"/>
<meta content="article" property="og:type"/>
<meta content="posts" property="article:section"/>
<meta content="2025-02-26T12:53:37+11:00" property="article:published_time"/>
<meta content="2025-02-26T12:53:37+11:00" property="article:modified_time"/>
<meta content="Neuro-Symbolic" property="article:tag"/>
<meta content="https://sino-huang.github.io/posts/neuro_symbolic_works_from_hamid_2024_2025/image-assets/cover.png" property="og:image"/>
<meta content="summary_large_image" name="twitter:card"/>
<meta content="https://sino-huang.github.io/posts/neuro_symbolic_works_from_hamid_2024_2025/image-assets/cover.png" name="twitter:image"/>
<meta content="Neuro Symbolic Works From A.Prof. Hamid @ Monash" name="twitter:title"/>
<meta content="There are three papers from A.Prof. Hamid Rezatofighi :https://vl4ai.erc.monash.edu/positions.html

NAVER: A Neuro-Symbolic Compositional Automaton for Visual Grounding
with Explicit Logic Reasoning
NEUSIS: A Compositional Neuro-Symbolic Framework for Autonomous Perception, Reasoning, and Planning in Complex UAV Search Missions
HYDRA: A Hyper Agent for Dynamic Compositional Visual Reasoning



 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57


# input bibtex here
1. 
@misc{cai2025naverneurosymboliccompositionalautomaton,
      title={NAVER: A Neuro-Symbolic Compositional Automaton for Visual Grounding with Explicit Logic Reasoning}, 
      author={Zhixi Cai and Fucai Ke and Simindokht Jahangard and Maria Garcia de la Banda and Reza Haffari and Peter J. Stuckey and Hamid Rezatofighi},
      year={2025},
      eprint={2502.00372},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2502.00372}, 
}

2. 

@article{DBLP:journals/corr/abs-2409-10196,
  author       = {Zhixi Cai and
                  Cristian Rojas Cardenas and
                  Kevin Leo and
                  Chenyuan Zhang and
                  Kal Backman and
                  Hanbing Li and
                  Boying Li and
                  Mahsa Ghorbanali and
                  Stavya Datta and
                  Lizhen Qu and
                  Julian Gutierrez Santiago and
                  Alexey Ignatiev and
                  Yuan{-}Fang Li and
                  Mor Vered and
                  Peter J. Stuckey and
                  Maria Garcia de la Banda and
                  Hamid Rezatofighi},
  title        = {{NEUSIS:} {A} Compositional Neuro-Symbolic Framework for Autonomous
                  Perception, Reasoning, and Planning in Complex {UAV} Search Missions},
  journal      = {CoRR},
  volume       = {abs/2409.10196},
  year         = {2024}
}



3. 
@inproceedings{DBLP:conf/eccv/KeCJWHR24,
  author       = {Fucai Ke and
                  Zhixi Cai and
                  Simindokht Jahangard and
                  Weiqing Wang and
                  Pari Delir Haghighi and
                  Hamid Rezatofighi},
  title        = {{HYDRA:} {A} Hyper Agent for Dynamic Compositional Visual Reasoning},
  booktitle    = {{ECCV} {(20)}},
  series       = {Lecture Notes in Computer Science},
  volume       = {15078},
  pages        = {132--149},
  publisher    = {Springer},
  year         = {2024}
}


NAVER: A Neuro-Symbolic Compositional Automaton for Visual Grounding
(https://arxiv.org/abs/2502.00372)" name="twitter:description"/>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://sino-huang.github.io/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Neuro Symbolic Works From A.Prof. Hamid @ Monash",
      "item": "https://sino-huang.github.io/posts/neuro_symbolic_works_from_hamid_2024_2025/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Neuro Symbolic Works From A.Prof. Hamid @ Monash",
  "name": "Neuro Symbolic Works From A.Prof. Hamid @ Monash",
  "description": "There are three papers from A.Prof. Hamid Rezatofighi :https://vl4ai.erc.monash.edu/positions.html\nNAVER: A Neuro-Symbolic Compositional Automaton for Visual Grounding with Explicit Logic Reasoning NEUSIS: A Compositional Neuro-Symbolic Framework for Autonomous Perception, Reasoning, and Planning in Complex UAV Search Missions HYDRA: A Hyper Agent for Dynamic Compositional Visual Reasoning 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 # input bibtex here 1. @misc{cai2025naverneurosymboliccompositionalautomaton, title={NAVER: A Neuro-Symbolic Compositional Automaton for Visual Grounding with Explicit Logic Reasoning}, author={Zhixi Cai and Fucai Ke and Simindokht Jahangard and Maria Garcia de la Banda and Reza Haffari and Peter J. Stuckey and Hamid Rezatofighi}, year={2025}, eprint={2502.00372}, archivePrefix={arXiv}, primaryClass={cs.CV}, url={https://arxiv.org/abs/2502.00372}, } 2. @article{DBLP:journals/corr/abs-2409-10196, author = {Zhixi Cai and Cristian Rojas Cardenas and Kevin Leo and Chenyuan Zhang and Kal Backman and Hanbing Li and Boying Li and Mahsa Ghorbanali and Stavya Datta and Lizhen Qu and Julian Gutierrez Santiago and Alexey Ignatiev and Yuan{-}Fang Li and Mor Vered and Peter J. Stuckey and Maria Garcia de la Banda and Hamid Rezatofighi}, title = {{NEUSIS:} {A} Compositional Neuro-Symbolic Framework for Autonomous Perception, Reasoning, and Planning in Complex {UAV} Search Missions}, journal = {CoRR}, volume = {abs/2409.10196}, year = {2024} } 3. @inproceedings{DBLP:conf/eccv/KeCJWHR24, author = {Fucai Ke and Zhixi Cai and Simindokht Jahangard and Weiqing Wang and Pari Delir Haghighi and Hamid Rezatofighi}, title = {{HYDRA:} {A} Hyper Agent for Dynamic Compositional Visual Reasoning}, booktitle = {{ECCV} {(20)}}, series = {Lecture Notes in Computer Science}, volume = {15078}, pages = {132--149}, publisher = {Springer}, year = {2024} } NAVER: A Neuro-Symbolic Compositional Automaton for Visual Grounding (https://arxiv.org/abs/2502.00372)\n",
  "keywords": [
    "neuro-symbolic"
  ],
  "articleBody": "There are three papers from A.Prof. Hamid Rezatofighi :https://vl4ai.erc.monash.edu/positions.html\nNAVER: A Neuro-Symbolic Compositional Automaton for Visual Grounding with Explicit Logic Reasoning NEUSIS: A Compositional Neuro-Symbolic Framework for Autonomous Perception, Reasoning, and Planning in Complex UAV Search Missions HYDRA: A Hyper Agent for Dynamic Compositional Visual Reasoning 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 # input bibtex here 1. @misc{cai2025naverneurosymboliccompositionalautomaton, title={NAVER: A Neuro-Symbolic Compositional Automaton for Visual Grounding with Explicit Logic Reasoning}, author={Zhixi Cai and Fucai Ke and Simindokht Jahangard and Maria Garcia de la Banda and Reza Haffari and Peter J. Stuckey and Hamid Rezatofighi}, year={2025}, eprint={2502.00372}, archivePrefix={arXiv}, primaryClass={cs.CV}, url={https://arxiv.org/abs/2502.00372}, } 2. @article{DBLP:journals/corr/abs-2409-10196, author = {Zhixi Cai and Cristian Rojas Cardenas and Kevin Leo and Chenyuan Zhang and Kal Backman and Hanbing Li and Boying Li and Mahsa Ghorbanali and Stavya Datta and Lizhen Qu and Julian Gutierrez Santiago and Alexey Ignatiev and Yuan{-}Fang Li and Mor Vered and Peter J. Stuckey and Maria Garcia de la Banda and Hamid Rezatofighi}, title = {{NEUSIS:} {A} Compositional Neuro-Symbolic Framework for Autonomous Perception, Reasoning, and Planning in Complex {UAV} Search Missions}, journal = {CoRR}, volume = {abs/2409.10196}, year = {2024} } 3. @inproceedings{DBLP:conf/eccv/KeCJWHR24, author = {Fucai Ke and Zhixi Cai and Simindokht Jahangard and Weiqing Wang and Pari Delir Haghighi and Hamid Rezatofighi}, title = {{HYDRA:} {A} Hyper Agent for Dynamic Compositional Visual Reasoning}, booktitle = {{ECCV} {(20)}}, series = {Lecture Notes in Computer Science}, volume = {15078}, pages = {132--149}, publisher = {Springer}, year = {2024} } NAVER: A Neuro-Symbolic Compositional Automaton for Visual Grounding (https://arxiv.org/abs/2502.00372)\nMotivation Contribution Some key terms Results Summary Potential future work NEUSIS: A Compositional Neuro-Symbolic Framework for Autonomous Perception, Reasoning, and Planning in Complex UAV Search Missions (https://arxiv.org/abs/2409.10196)\nHYDRA: A Hyper Agent for Dynamic Compositional Visual Reasoning (https://arxiv.org/abs/2403.12884)\n",
  "wordCount" : "342",
  "inLanguage": "en",
  "image":"https://sino-huang.github.io/posts/neuro_symbolic_works_from_hamid_2024_2025/image-assets/cover.png","datePublished": "2025-02-26T12:53:37+11:00",
  "dateModified": "2025-02-26T12:53:37+11:00",
  "author":{
    "@type": "Person",
    "name": "Sukai Huang"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://sino-huang.github.io/posts/neuro_symbolic_works_from_hamid_2024_2025/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Sukai Huang",
    "logo": {
      "@type": "ImageObject",
      "url": "https://sino-huang.github.io/favicon.ico"
    }
  }
}
</script>
</head>
<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>
<header class="header">
<nav class="nav">
<div class="logo">
<a accesskey="h" href="https://sino-huang.github.io/" title="Sukai Huang (Alt + H)">Sukai Huang</a>
<div class="logo-switches">
<button accesskey="t" id="theme-toggle" title="(Alt + T)">
<svg fill="none" height="18" id="moon" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewbox="0 0 24 24" width="24" xmlns="http://www.w3.org/2000/svg">
<path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
</svg>
<svg fill="none" height="18" id="sun" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewbox="0 0 24 24" width="24" xmlns="http://www.w3.org/2000/svg">
<circle cx="12" cy="12" r="5"></circle>
<line x1="12" x2="12" y1="1" y2="3"></line>
<line x1="12" x2="12" y1="21" y2="23"></line>
<line x1="4.22" x2="5.64" y1="4.22" y2="5.64"></line>
<line x1="18.36" x2="19.78" y1="18.36" y2="19.78"></line>
<line x1="1" x2="3" y1="12" y2="12"></line>
<line x1="21" x2="23" y1="12" y2="12"></line>
<line x1="4.22" x2="5.64" y1="19.78" y2="18.36"></line>
<line x1="18.36" x2="19.78" y1="5.64" y2="4.22"></line>
</svg>
</button>
</div>
</div>
<ul id="menu">
<li>
<a href="https://sino-huang.github.io/biography/" title="Biography">
<span>Biography</span>
</a>
</li>
<li>
<a href="https://sino-huang.github.io/archives" title="Archive">
<span>Archive</span>
</a>
</li>
<li>
<a href="https://sino-huang.github.io/tags/" title="Tags">
<span>Tags</span>
</a>
</li>
<li>
<a href="https://sino-huang.github.io/categories/" title="Categories">
<span>Categories</span>
</a>
</li>
<li>
<a accesskey="/" href="https://sino-huang.github.io/search/" title="Search (Alt + /)">
<span>Search</span>
</a>
</li>
</ul>
</nav>
</header>
<main class="main">
<article class="post-single">
<header class="post-header">
<div class="breadcrumbs"><a href="https://sino-huang.github.io/">Home</a> » <a href="https://sino-huang.github.io/posts/">Posts</a></div>
<h1 class="post-title entry-hint-parent">
      Neuro Symbolic Works From A.Prof. Hamid @ Monash
    </h1>
<div class="post-meta"><span title="2025-02-26 12:53:37 +1100 AEDT">February 26, 2025</span> · 2 min · 342 words · Sukai Huang | <a href="mailto:sukaih@student.unimelb.edu.au/posts/neuro_symbolic_works_from_hamid_2024_2025/index.md" rel="noopener noreferrer" target="_blank">Submit a report</a>
</div>
</header>
<figure class="entry-cover"><img alt="" loading="eager" src="https://sino-huang.github.io/posts/neuro_symbolic_works_from_hamid_2024_2025/image-assets/cover.png"/>
<p><text></text></p>
</figure><div class="toc">
<details>
<summary accesskey="c" title="(Alt + C)">
<span class="details">Table of Contents</span>
</summary>
<div class="inner"><ul>
<li>
<a aria-label="NAVER: A Neuro-Symbolic Compositional Automaton for Visual Grounding" href="#naver-a-neuro-symbolic-compositional-automaton-for-visual-grounding">NAVER: A Neuro-Symbolic Compositional Automaton for Visual Grounding</a><ul>
<li>
<a aria-label="Motivation" href="#motivation">Motivation</a></li>
<li>
<a aria-label="Contribution" href="#contribution">Contribution</a></li>
<li>
<a aria-label="Some key terms" href="#some-key-terms">Some key terms</a></li></ul>
</li>
<li>
<a aria-label="Results" href="#results">Results</a></li>
<li>
<a aria-label="Summary" href="#summary">Summary</a></li>
<li>
<a aria-label="Potential future work" href="#potential-future-work">Potential future work</a></li>
<li>
<a aria-label="NEUSIS: A Compositional Neuro-Symbolic Framework for Autonomous Perception, Reasoning, and Planning in Complex UAV Search Missions" href="#neusis-a-compositional-neuro-symbolic-framework-for-autonomous-perception-reasoning-and-planning-in-complex-uav-search-missions">NEUSIS: A Compositional Neuro-Symbolic Framework for Autonomous Perception, Reasoning, and Planning in Complex UAV Search Missions</a></li>
<li>
<a aria-label="HYDRA: A Hyper Agent for Dynamic Compositional Visual Reasoning" href="#hydra-a-hyper-agent-for-dynamic-compositional-visual-reasoning">HYDRA: A Hyper Agent for Dynamic Compositional Visual Reasoning</a>
</li>
</ul>
</div>
</details>
</div>
<div class="post-content"><p>There are three papers from A.Prof. Hamid Rezatofighi :https://vl4ai.erc.monash.edu/positions.html</p>
<ol>
<li><a href="https://arxiv.org/abs/2502.00372">NAVER: A Neuro-Symbolic Compositional Automaton for Visual Grounding
with Explicit Logic Reasoning</a></li>
<li><a href="https://arxiv.org/abs/2409.10196">NEUSIS: A Compositional Neuro-Symbolic Framework for Autonomous Perception, Reasoning, and Planning in Complex UAV Search Missions</a></li>
<li><a href="https://arxiv.org/abs/2403.12884">HYDRA: A Hyper Agent for Dynamic Compositional Visual Reasoning</a></li>
</ol>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma" tabindex="0"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span><span class="lnt">52
</span><span class="lnt">53
</span><span class="lnt">54
</span><span class="lnt">55
</span><span class="lnt">56
</span><span class="lnt">57
</span></code></pre></td>
<td class="lntd">
<pre class="chroma" tabindex="0"><code class="language-bibtex" data-lang="bibtex"><span class="line"><span class="cl"><span class="c"># input bibtex here</span>
</span></span><span class="line"><span class="cl"><span class="c">1. </span>
</span></span><span class="line"><span class="cl"><span class="nc">@misc</span><span class="p">{</span><span class="nl">cai2025naverneurosymboliccompositionalautomaton</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">      <span class="na">title</span><span class="p">=</span><span class="s">{NAVER: A Neuro-Symbolic Compositional Automaton for Visual Grounding with Explicit Logic Reasoning}</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">      <span class="na">author</span><span class="p">=</span><span class="s">{Zhixi Cai and Fucai Ke and Simindokht Jahangard and Maria Garcia de la Banda and Reza Haffari and Peter J. Stuckey and Hamid Rezatofighi}</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">      <span class="na">year</span><span class="p">=</span><span class="s">{2025}</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">      <span class="na">eprint</span><span class="p">=</span><span class="s">{2502.00372}</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">      <span class="na">archivePrefix</span><span class="p">=</span><span class="s">{arXiv}</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">      <span class="na">primaryClass</span><span class="p">=</span><span class="s">{cs.CV}</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">      <span class="na">url</span><span class="p">=</span><span class="s">{https://arxiv.org/abs/2502.00372}</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c">2. </span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nc">@article</span><span class="p">{</span><span class="nl">DBLP:journals/corr/abs-2409-10196</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">  <span class="na">author</span>       <span class="p">=</span> <span class="s">{Zhixi Cai and
</span></span></span><span class="line"><span class="cl"><span class="s">                  Cristian Rojas Cardenas and
</span></span></span><span class="line"><span class="cl"><span class="s">                  Kevin Leo and
</span></span></span><span class="line"><span class="cl"><span class="s">                  Chenyuan Zhang and
</span></span></span><span class="line"><span class="cl"><span class="s">                  Kal Backman and
</span></span></span><span class="line"><span class="cl"><span class="s">                  Hanbing Li and
</span></span></span><span class="line"><span class="cl"><span class="s">                  Boying Li and
</span></span></span><span class="line"><span class="cl"><span class="s">                  Mahsa Ghorbanali and
</span></span></span><span class="line"><span class="cl"><span class="s">                  Stavya Datta and
</span></span></span><span class="line"><span class="cl"><span class="s">                  Lizhen Qu and
</span></span></span><span class="line"><span class="cl"><span class="s">                  Julian Gutierrez Santiago and
</span></span></span><span class="line"><span class="cl"><span class="s">                  Alexey Ignatiev and
</span></span></span><span class="line"><span class="cl"><span class="s">                  Yuan{-}Fang Li and
</span></span></span><span class="line"><span class="cl"><span class="s">                  Mor Vered and
</span></span></span><span class="line"><span class="cl"><span class="s">                  Peter J. Stuckey and
</span></span></span><span class="line"><span class="cl"><span class="s">                  Maria Garcia de la Banda and
</span></span></span><span class="line"><span class="cl"><span class="s">                  Hamid Rezatofighi}</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">  <span class="na">title</span>        <span class="p">=</span> <span class="s">{{NEUSIS:} {A} Compositional Neuro-Symbolic Framework for Autonomous
</span></span></span><span class="line"><span class="cl"><span class="s">                  Perception, Reasoning, and Planning in Complex {UAV} Search Missions}</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">  <span class="na">journal</span>      <span class="p">=</span> <span class="s">{CoRR}</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">  <span class="na">volume</span>       <span class="p">=</span> <span class="s">{abs/2409.10196}</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">  <span class="na">year</span>         <span class="p">=</span> <span class="s">{2024}</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c">3. </span>
</span></span><span class="line"><span class="cl"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">DBLP:conf/eccv/KeCJWHR24</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">  <span class="na">author</span>       <span class="p">=</span> <span class="s">{Fucai Ke and
</span></span></span><span class="line"><span class="cl"><span class="s">                  Zhixi Cai and
</span></span></span><span class="line"><span class="cl"><span class="s">                  Simindokht Jahangard and
</span></span></span><span class="line"><span class="cl"><span class="s">                  Weiqing Wang and
</span></span></span><span class="line"><span class="cl"><span class="s">                  Pari Delir Haghighi and
</span></span></span><span class="line"><span class="cl"><span class="s">                  Hamid Rezatofighi}</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">  <span class="na">title</span>        <span class="p">=</span> <span class="s">{{HYDRA:} {A} Hyper Agent for Dynamic Compositional Visual Reasoning}</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">  <span class="na">booktitle</span>    <span class="p">=</span> <span class="s">{{ECCV} {(20)}}</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">  <span class="na">series</span>       <span class="p">=</span> <span class="s">{Lecture Notes in Computer Science}</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">  <span class="na">volume</span>       <span class="p">=</span> <span class="s">{15078}</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">  <span class="na">pages</span>        <span class="p">=</span> <span class="s">{132--149}</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">  <span class="na">publisher</span>    <span class="p">=</span> <span class="s">{Springer}</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">  <span class="na">year</span>         <span class="p">=</span> <span class="s">{2024}</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="naver-a-neuro-symbolic-compositional-automaton-for-visual-grounding">NAVER: A Neuro-Symbolic Compositional Automaton for Visual Grounding<a aria-hidden="true" class="anchor" hidden="" href="#naver-a-neuro-symbolic-compositional-automaton-for-visual-grounding">#</a></h2>
<p>(<a href="https://arxiv.org/abs/2502.00372">https://arxiv.org/abs/2502.00372</a>)</p>
<h3 id="motivation">Motivation<a aria-hidden="true" class="anchor" hidden="" href="#motivation">#</a></h3>
<p><img alt="image-20250226133108027" loading="lazy" src="/posts/neuro_symbolic_works_from_hamid_2024_2025/image-assets/image-20250226133108027.png"/></p>
<h3 id="contribution">Contribution<a aria-hidden="true" class="anchor" hidden="" href="#contribution">#</a></h3>
<h3 id="some-key-terms">Some key terms<a aria-hidden="true" class="anchor" hidden="" href="#some-key-terms">#</a></h3>
<h2 id="results">Results<a aria-hidden="true" class="anchor" hidden="" href="#results">#</a></h2>
<h2 id="summary">Summary<a aria-hidden="true" class="anchor" hidden="" href="#summary">#</a></h2>
<h2 id="potential-future-work">Potential future work<a aria-hidden="true" class="anchor" hidden="" href="#potential-future-work">#</a></h2>
<h2 id="neusis-a-compositional-neuro-symbolic-framework-for-autonomous-perception-reasoning-and-planning-in-complex-uav-search-missions">NEUSIS: A Compositional Neuro-Symbolic Framework for Autonomous Perception, Reasoning, and Planning in Complex UAV Search Missions<a aria-hidden="true" class="anchor" hidden="" href="#neusis-a-compositional-neuro-symbolic-framework-for-autonomous-perception-reasoning-and-planning-in-complex-uav-search-missions">#</a></h2>
<p>(<a href="https://arxiv.org/abs/2409.10196">https://arxiv.org/abs/2409.10196</a>)</p>
<h2 id="hydra-a-hyper-agent-for-dynamic-compositional-visual-reasoning">HYDRA: A Hyper Agent for Dynamic Compositional Visual Reasoning<a aria-hidden="true" class="anchor" hidden="" href="#hydra-a-hyper-agent-for-dynamic-compositional-visual-reasoning">#</a></h2>
<p>(<a href="https://arxiv.org/abs/2403.12884">https://arxiv.org/abs/2403.12884</a>)</p>
</div>
<footer class="post-footer">
<ul class="post-tags">
<li><a href="https://sino-huang.github.io/tags/neuro-symbolic/">Neuro-Symbolic</a></li>
</ul>
<nav class="paginav">
<a class="next" href="https://sino-huang.github.io/posts/awesome_llm_reasoning_capability_papers/">
<span class="title">Next »</span>
<br/>
<span>Awesome LLMs Reasoning Abilities Papers</span>
</a>
</nav>
<ul class="share-buttons">
<li>
<a aria-label="share Neuro Symbolic Works From A.Prof. Hamid @ Monash on x" href="https://x.com/intent/tweet/?text=Neuro%20Symbolic%20Works%20From%20A.Prof.%20Hamid%20%40%20Monash&amp;url=https%3a%2f%2fsino-huang.github.io%2fposts%2fneuro_symbolic_works_from_hamid_2024_2025%2f&amp;hashtags=neuro-symbolic" rel="noopener noreferrer" target="_blank">
<svg fill="currentColor" height="30px" version="1.1" viewbox="0 0 512 512" width="30px" xml:space="preserve">
<path d="M512 62.554 L 512 449.446 C 512 483.97 483.97 512 449.446 512 L 62.554 512 C 28.03 512 0 483.97 0 449.446 L 0 62.554 C 0 28.03 28.029 0 62.554 0 L 449.446 0 C 483.971 0 512 28.03 512 62.554 Z M 269.951 190.75 L 182.567 75.216 L 56 75.216 L 207.216 272.95 L 63.9 436.783 L 125.266 436.783 L 235.9 310.383 L 332.567 436.783 L 456 436.783 L 298.367 228.367 L 432.367 75.216 L 371.033 75.216 Z M 127.633 110 L 164.101 110 L 383.481 400.065 L 349.5 400.065 Z"></path>
</svg>
</a>
</li>
<li>
<a aria-label="share Neuro Symbolic Works From A.Prof. Hamid @ Monash on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fsino-huang.github.io%2fposts%2fneuro_symbolic_works_from_hamid_2024_2025%2f&amp;title=Neuro%20Symbolic%20Works%20From%20A.Prof.%20Hamid%20%40%20Monash&amp;summary=Neuro%20Symbolic%20Works%20From%20A.Prof.%20Hamid%20%40%20Monash&amp;source=https%3a%2f%2fsino-huang.github.io%2fposts%2fneuro_symbolic_works_from_hamid_2024_2025%2f" rel="noopener noreferrer" target="_blank">
<svg fill="currentColor" height="30px" version="1.1" viewbox="0 0 512 512" width="30px" xml:space="preserve">
<path d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z"></path>
</svg>
</a>
</li>
<li>
<a aria-label="share Neuro Symbolic Works From A.Prof. Hamid @ Monash on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fsino-huang.github.io%2fposts%2fneuro_symbolic_works_from_hamid_2024_2025%2f&amp;title=Neuro%20Symbolic%20Works%20From%20A.Prof.%20Hamid%20%40%20Monash" rel="noopener noreferrer" target="_blank">
<svg fill="currentColor" height="30px" version="1.1" viewbox="0 0 512 512" width="30px" xml:space="preserve">
<path d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-3.446,265.638c0,-22.964 -18.616,-41.58 -41.58,-41.58c-11.211,0 -21.361,4.457 -28.841,11.666c-28.424,-20.508 -67.586,-33.757 -111.204,-35.278l18.941,-89.121l61.884,13.157c0.756,15.734 13.642,28.29 29.56,28.29c16.407,0 29.706,-13.299 29.706,-29.701c0,-16.403 -13.299,-29.702 -29.706,-29.702c-11.666,0 -21.657,6.792 -26.515,16.578l-69.105,-14.69c-1.922,-0.418 -3.939,-0.042 -5.585,1.036c-1.658,1.073 -2.811,2.761 -3.224,4.686l-21.152,99.438c-44.258,1.228 -84.046,14.494 -112.837,35.232c-7.468,-7.164 -17.589,-11.591 -28.757,-11.591c-22.965,0 -41.585,18.616 -41.585,41.58c0,16.896 10.095,31.41 24.568,37.918c-0.639,4.135 -0.99,8.328 -0.99,12.576c0,63.977 74.469,115.836 166.33,115.836c91.861,0 166.334,-51.859 166.334,-115.836c0,-4.218 -0.347,-8.387 -0.977,-12.493c14.564,-6.47 24.735,-21.034 24.735,-38.001Zm-119.474,108.193c-20.27,20.241 -59.115,21.816 -70.534,21.816c-11.428,0 -50.277,-1.575 -70.522,-21.82c-3.007,-3.008 -3.007,-7.882 0,-10.889c3.003,-2.999 7.882,-3.003 10.885,0c12.777,12.781 40.11,17.317 59.637,17.317c19.522,0 46.86,-4.536 59.657,-17.321c3.016,-2.999 7.886,-2.995 10.885,0.008c3.008,3.011 3.003,7.882 -0.008,10.889Zm-5.23,-48.781c-16.373,0 -29.701,-13.324 -29.701,-29.698c0,-16.381 13.328,-29.714 29.701,-29.714c16.378,0 29.706,13.333 29.706,29.714c0,16.374 -13.328,29.698 -29.706,29.698Zm-160.386,-29.702c0,-16.381 13.328,-29.71 29.714,-29.71c16.369,0 29.689,13.329 29.689,29.71c0,16.373 -13.32,29.693 -29.689,29.693c-16.386,0 -29.714,-13.32 -29.714,-29.693Z"></path>
</svg>
</a>
</li>
<li>
<a aria-label="share Neuro Symbolic Works From A.Prof. Hamid @ Monash on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fsino-huang.github.io%2fposts%2fneuro_symbolic_works_from_hamid_2024_2025%2f" rel="noopener noreferrer" target="_blank">
<svg fill="currentColor" height="30px" version="1.1" viewbox="0 0 512 512" width="30px" xml:space="preserve">
<path d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-106.468,0l0,-192.915l66.6,0l12.672,-82.621l-79.272,0l0,-53.617c0,-22.603 11.073,-44.636 46.58,-44.636l36.042,0l0,-70.34c0,0 -32.71,-5.582 -63.982,-5.582c-65.288,0 -107.96,39.569 -107.96,111.204l0,62.971l-72.573,0l0,82.621l72.573,0l0,192.915l-191.104,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Z"></path>
</svg>
</a>
</li>
<li>
<a aria-label="share Neuro Symbolic Works From A.Prof. Hamid @ Monash on whatsapp" href="https://api.whatsapp.com/send?text=Neuro%20Symbolic%20Works%20From%20A.Prof.%20Hamid%20%40%20Monash%20-%20https%3a%2f%2fsino-huang.github.io%2fposts%2fneuro_symbolic_works_from_hamid_2024_2025%2f" rel="noopener noreferrer" target="_blank">
<svg fill="currentColor" height="30px" version="1.1" viewbox="0 0 512 512" width="30px" xml:space="preserve">
<path d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-58.673,127.703c-33.842,-33.881 -78.847,-52.548 -126.798,-52.568c-98.799,0 -179.21,80.405 -179.249,179.234c-0.013,31.593 8.241,62.428 23.927,89.612l-25.429,92.884l95.021,-24.925c26.181,14.28 55.659,21.807 85.658,21.816l0.074,0c98.789,0 179.206,-80.413 179.247,-179.243c0.018,-47.895 -18.61,-92.93 -52.451,-126.81Zm-126.797,275.782l-0.06,0c-26.734,-0.01 -52.954,-7.193 -75.828,-20.767l-5.441,-3.229l-56.386,14.792l15.05,-54.977l-3.542,-5.637c-14.913,-23.72 -22.791,-51.136 -22.779,-79.287c0.033,-82.142 66.867,-148.971 149.046,-148.971c39.793,0.014 77.199,15.531 105.329,43.692c28.128,28.16 43.609,65.592 43.594,105.4c-0.034,82.149 -66.866,148.983 -148.983,148.984Zm81.721,-111.581c-4.479,-2.242 -26.499,-13.075 -30.604,-14.571c-4.105,-1.495 -7.091,-2.241 -10.077,2.241c-2.986,4.483 -11.569,14.572 -14.182,17.562c-2.612,2.988 -5.225,3.364 -9.703,1.12c-4.479,-2.241 -18.91,-6.97 -36.017,-22.23c-13.314,-11.876 -22.304,-26.542 -24.916,-31.026c-2.612,-4.484 -0.279,-6.908 1.963,-9.14c2.016,-2.007 4.48,-5.232 6.719,-7.847c2.24,-2.615 2.986,-4.484 4.479,-7.472c1.493,-2.99 0.747,-5.604 -0.374,-7.846c-1.119,-2.241 -10.077,-24.288 -13.809,-33.256c-3.635,-8.733 -7.327,-7.55 -10.077,-7.688c-2.609,-0.13 -5.598,-0.158 -8.583,-0.158c-2.986,0 -7.839,1.121 -11.944,5.604c-4.105,4.484 -15.675,15.32 -15.675,37.364c0,22.046 16.048,43.342 18.287,46.332c2.24,2.99 31.582,48.227 76.511,67.627c10.685,4.615 19.028,7.371 25.533,9.434c10.728,3.41 20.492,2.929 28.209,1.775c8.605,-1.285 26.499,-10.833 30.231,-21.295c3.732,-10.464 3.732,-19.431 2.612,-21.298c-1.119,-1.869 -4.105,-2.99 -8.583,-5.232Z"></path>
</svg>
</a>
</li>
<li>
<a aria-label="share Neuro Symbolic Works From A.Prof. Hamid @ Monash on telegram" href="https://telegram.me/share/url?text=Neuro%20Symbolic%20Works%20From%20A.Prof.%20Hamid%20%40%20Monash&amp;url=https%3a%2f%2fsino-huang.github.io%2fposts%2fneuro_symbolic_works_from_hamid_2024_2025%2f" rel="noopener noreferrer" target="_blank">
<svg fill="currentColor" height="30px" version="1.1" viewbox="2 2 28 28" width="30px" xml:space="preserve">
<path d="M26.49,29.86H5.5a3.37,3.37,0,0,1-2.47-1,3.35,3.35,0,0,1-1-2.47V5.48A3.36,3.36,0,0,1,3,3,3.37,3.37,0,0,1,5.5,2h21A3.38,3.38,0,0,1,29,3a3.36,3.36,0,0,1,1,2.46V26.37a3.35,3.35,0,0,1-1,2.47A3.38,3.38,0,0,1,26.49,29.86Zm-5.38-6.71a.79.79,0,0,0,.85-.66L24.73,9.24a.55.55,0,0,0-.18-.46.62.62,0,0,0-.41-.17q-.08,0-16.53,6.11a.59.59,0,0,0-.41.59.57.57,0,0,0,.43.52l4,1.24,1.61,4.83a.62.62,0,0,0,.63.43.56.56,0,0,0,.4-.17L16.54,20l4.09,3A.9.9,0,0,0,21.11,23.15ZM13.8,20.71l-1.21-4q8.72-5.55,8.78-5.55c.15,0,.23,0,.23.16a.18.18,0,0,1,0,.06s-2.51,2.3-7.52,6.8Z"></path>
</svg>
</a>
</li>
<li>
<a aria-label="share Neuro Symbolic Works From A.Prof. Hamid @ Monash on ycombinator" href="https://news.ycombinator.com/submitlink?t=Neuro%20Symbolic%20Works%20From%20A.Prof.%20Hamid%20%40%20Monash&amp;u=https%3a%2f%2fsino-huang.github.io%2fposts%2fneuro_symbolic_works_from_hamid_2024_2025%2f" rel="noopener noreferrer" target="_blank">
<svg fill="currentColor" height="30px" version="1.1" viewbox="0 0 512 512" width="30px" xml:space="preserve" xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape">
<path d="M449.446 0C483.971 0 512 28.03 512 62.554L512 449.446C512 483.97 483.97 512 449.446 512L62.554 512C28.03 512 0 483.97 0 449.446L0 62.554C0 28.03 28.029 0 62.554 0L449.446 0ZM183.8767 87.9921H121.8427L230.6673 292.4508V424.0079H281.3328V292.4508L390.1575 87.9921H328.1233L256 238.2489z"></path>
</svg>
</a>
</li>
</ul>
</footer>
</article>
</main>
<footer class="footer">
<span>© 2025 <a href="https://sino-huang.github.io/">Sukai Huang</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &amp;
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
</span>
</footer>
<a accesskey="g" aria-label="go to top" class="top-link" href="#top" id="top-link" title="Go to Top (Alt + G)">
<svg fill="currentColor" viewbox="0 0 12 6" xmlns="http://www.w3.org/2000/svg">
<path d="M12 6H0l6-6z"></path>
</svg>
</a>
<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>
</html>
